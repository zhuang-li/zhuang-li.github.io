---
title: "Unsupervised Pre-training With Seq2Seq Reconstruction Loss for Deep Relation Extraction Models"
collection: publications
permalink: /publication/2016-unsupervised-relation-extraction
excerpt: 'This paper is about using the pre-training technique to improve the relation extraction performance.'
date: 2016-12
venue: 'ALTA 2016'
paperurl: 'https://www.aclweb.org/anthology/U16-1006/'
---
This paper is about the number 2. The number 3 is left for future work.

[Download paper here](https://www.aclweb.org/anthology/U16-1006/)

Citation: 
--
```
@inproceedings{li-etal-2016-unsupervised,
    title = "Unsupervised Pre-training With {S}eq2{S}eq Reconstruction Loss for Deep Relation Extraction Models",
    author = "Li, Zhuang  and
      Qu, Lizhen  and
      Xu, Qiongkai  and
      Johnson, Mark",
    booktitle = "Proceedings of the Australasian Language Technology Association Workshop 2016",
    month = dec,
    year = "2016",
    address = "Melbourne, Australia",
    url = "https://www.aclweb.org/anthology/U16-1006",
    pages = "54--64",
}
```
